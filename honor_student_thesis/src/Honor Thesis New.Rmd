---
title: "Honor Thesis 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

---
title: "Thesis Honor"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

#a) Part 1: Package Installed
```{r}
install.packages("tidyverse") 
install.packages("psych") 
install.packages("ggplot2")
library(tidyverse) 
library(psych)
```

#b) Data Import
```{r}
dt <- read_csv("Cleaned.csv")
dt
```

#c) Likability分开alpha
moderator is the gender of participants
```{r}
dt_likability_1 <- dt %>% # this is the "pipe" function
  select(starts_with("14、喜爱度"), starts_with("18、喜爱度"), starts_with("22、好感度"))
alpha(dt_likability_1) # This is the "alpha" function from the psych package to calculate Cronbach's alpha --- one of the most commonly used metric for reliability

dt_likability_2 <- dt %>% # this is the "pipe" function
  select(starts_with("30、喜爱度"))
alpha(dt_likability_2)
```
#d)Likability 分开mean
```{r}
dt <- dt %>%
  mutate(likability_1 = rowMeans(select(dt,  
                                starts_with("14、喜爱度"),
                                starts_with("18、喜爱度"),
                                starts_with("22、好感度")), 
                         na.rm=T)) %>%
  mutate(likability_2 = rowMeans(select(dt,  
                                 starts_with("30、喜爱度")), 
                         na.rm=T))

```

#e) conditions-likability 
```{r}
dt_f <- dt %>% 
  filter(Gender == 1)

dt_per_likability_f <- dt_f %>% 
  filter(Condition == "Perfect") %>%
  select(likability_1)

dt_ave_likability_f <- dt_f %>% 
  filter(Condition == "Average") %>%
  select(likability_1)

dt_over_likability_f <- dt_f %>% 
  filter(Condition == "Overweight") %>%
  select(likability_1)

```

```{r}
dt_m <- dt %>% 
  filter(Gender == 2)

dt_per_likability_2 <- dt_m %>% 
  filter(Condition == "Perfect") %>%
  select(likability_2)

dt_ave_likability_2 <- dt_m %>% 
  filter(Condition == "Average") %>%
  select(likability_2)

dt_over_likability_2 <- dt_m %>% 
  filter(Condition == "Overweight") %>%
  select(likability_2)
```

```{r}
mean(dt_per_likability_1$likability_1)
sd(dt_per_likability_1$likability_1)

mean(dt_per_likability_2$likability_2)
sd(dt_per_likability_2$likability_2)

mean(dt_per_likability_3$likability_3)
sd(dt_per_likability_3$likability_3)

mean(dt_per_likability_4$likability_4)
sd(dt_per_likability_4$likability_4)
```

#f)Likability 画图
```{r}
library(ggplot2) # ggplot2 is R's powerhouse for visualization

ggplot(dt, 
       aes(x=likability_1)) + 
  geom_histogram(binwidth=0.1)
```

```{r}
library(tidyverse)
library(rstatix)
likability_1 <- lm(likability_1~condition2, data = dt)

summary(mod_fear_3)
confint(mod_fear_3)
```

```{r}
library(Publish)
dt_plot_means <- ci.mean(likability_1~Condition,
                         data=dt_m)
dt_plot_means <- as_tibble(dt_plot_means)
dt_plot_means <- as_tibble(dt_plot_means)%>%
  select(labels, mean, lower, upper)
library(ggplot2)
library(ggsci)
library(ggpubr)

apatheme=theme_bw()+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        text=element_text(family='sans',size=10),
        legend.title = element_text(size = 10))

dodge = position_dodge(width=0.8)

plot.fear <- ggplot(dt_plot_means, # Your dataset that contains labels, means, and lower and upper bounds
                    aes(x = labels, # this corresponds to the variable that specifies groups/conditions
                        y = mean,  # this corresponds to the variable that records group means
                        fill = labels))+ # this corresponds to the variable that specifies groups/conditions
  scale_fill_nejm()+                    # I am using the color panel for the New England Journal of Medicine. You could change to a different one. 
  geom_bar(stat='identity', position = dodge, width = 0.8)+  
  coord_cartesian(ylim=c(1,5))+         # you should use the scale of your DV (5 points? 7 points?)
  geom_errorbar(aes(ymin = lower,       # this corresponds to the variable that records the lower bound for the 95% CI.
                    ymax = upper),      # this corresponds to the variable that records the lower bound for the 95% CI.
                size=0.5, 
                position=dodge, 
                width=0.06, 
                colour="gray30")+
  apatheme+
  ylab("95% CIs of Group Means")+       # label/name of the Y axis --> Feel free to change this. 
  xlab("Conditions")                    # label/name of the X axis --> Feel free to change this. 

plot.fear

library(officer)
library(rvg)

## Output to PPT
p_dml <- rvg::dml(ggobj = plot.fear) # name of your ggplot2 object

read_pptx() %>%
    add_slide(layout = "Title and Content", master = "Office Theme") %>%
    ph_with(value = p_dml, 
            location = ph_location(type = "body",
                                   width = 10, # You can change the width of your output ppt
                                   height = 5)) %>% # You can change the height of your output ppt
    print(target = "figure_group_means.pptx")
```

#g)shopping intention分开alpha
```{r}
dt_si_myself_1 <- dt %>% 
  select(starts_with("16、购买意愿2"), starts_with("15、购买意愿1"), 
         starts_with("19、购买意愿1"), starts_with("20、购买意愿2"),
         starts_with("23、购买意愿1"), starts_with("24、购买意愿2"))
alpha(dt_si_myself_1) # This is the "alpha" function from the psych package to calculate Cronbach's alpha --- one of the most commonly used metric for reliability

dt_si_myself_2 <- dt %>% 
  select(starts_with("31、购买意愿1"), starts_with("32、购买意愿2"))
alpha(dt_si_myself_2)

dt_si_family_1 <- dt %>% 
  select(starts_with("16、购买意愿3"),
         starts_with("20、购买意愿3"),
         starts_with("24、购买意愿3"))
alpha(dt_si_family_1)

dt_si_family_2 <- dt %>% 
  select(starts_with("32、购买意愿4"))
alpha(dt_si_family_2)
```

#h)shopping intention 分开mean
```{r}
dt <- dt %>%
  mutate(si_myself_1 = rowMeans(select(dt,  
                                starts_with("15、购买意愿1"),  
                                starts_with("16、购买意愿2"),
                                starts_with("19、购买意愿1"),
                                starts_with("20、购买意愿2"),
                                starts_with("23、购买意愿1"),
                                starts_with("24、购买意愿2")),
                         na.rm=T)) %>%
  mutate(si_myself_2 = rowMeans(select(dt,  
                                 starts_with("31、购买意愿1"),
                                 starts_with("32、购买意愿2")), 
                         na.rm=T)) %>%
  mutate(si_family_1 = rowMeans(select(dt,  
                                 starts_with("16、购买意愿3"),
                                 starts_with("20、购买意愿3"),
                                 starts_with("24、购买意愿3")), 
                         na.rm=T)) %>%
  mutate(si_family_2 = rowMeans(select(dt,  
                                 starts_with("32、购买意愿3")), 
                         na.rm=T))

```
#i) conditions-shopping intentions
```{r}
dt_m <- dt

dt_per_likability_1 <- dt_m %>% 
  filter(Condition == "Perfect") %>%
  select(likability_1)

dt_ave_likability_1 <- dt_m %>% 
  filter(Condition == "Average") %>%
  select(likability_1)

dt_over_likability_1 <- dt_m %>% 
  filter(Condition == "Overweight") %>%
  select(likability_1)
```

```{r}
dt_per_likability_2 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_2)

dt_ave_likability_2 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_2)

dt_over_likability_2 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_2)
```

```{r}
dt_per_likability_3 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_3)

dt_ave_likability_3 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_3)

dt_over_likability_3 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_3)
```

```{r}
dt_per_likability_4 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_4)

dt_ave_likability_4 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_4)

dt_over_likability_4 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_4)
```

```{r}
mean(dt_per_likability_1$likability_1)
sd(dt_per_likability_1$likability_1)

mean(dt_per_likability_2$likability_2)
sd(dt_per_likability_2$likability_2)

mean(dt_per_likability_3$likability_3)
sd(dt_per_likability_3$likability_3)

mean(dt_per_likability_4$likability_4)
sd(dt_per_likability_4$likability_4)
```

#j)Shopping intention 画图
```{r}
install.packages("rstatix")
library(rstatix)
```

```{r}
install.packages("Publish")
library(Publish)
```
```{r}
dt_plot_means <- ci.mean(soc_comp~condition,
                         data=dt)
dt_plot_means <- as_tibble(dt_plot_means)
dt_plot_means <- as_tibble(dt_plot_means)%>%
  select(labels, mean, lower, upper)
```

```{r}
install.packages("ggpubr")
install.packages("ggsci")

library(ggplot2)
library(ggsci)
library(ggpubr)

apatheme=theme_bw()+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        text=element_text(family='sans',size=10),
        legend.title = element_text(size = 10))

dodge = position_dodge(width=0.8)
```

```{r}
plot.soc_comp <- ggplot(dt_plot_means, # Your dataset that contains labels, means, and lower and upper bounds
                    aes(x = labels, # this corresponds to the variable that specifies groups/conditions
                        y = mean,  # this corresponds to the variable that records group means
                        fill = labels))+ # this corresponds to the variable that specifies groups/conditions
  scale_fill_nejm()+                    # I am using the color panel for the New England Journal of Medicine. You could change to a different one. 
  geom_bar(stat='identity', position = dodge, width = 0.8)+  
  coord_cartesian(ylim=c(1,5))+         # you should use the scale of your DV (5 points? 7 points?)
  geom_errorbar(aes(ymin = lower,       # this corresponds to the variable that records the lower bound for the 95% CI.
                    ymax = upper),      # this corresponds to the variable that records the lower bound for the 95% CI.
                size=0.5, 
                position=dodge, 
                width=0.06, 
                colour="gray30")+
  apatheme+
  ylab("95% CIs of Group Means")+       # label/name of the Y axis --> Feel free to change this. 
  xlab("Conditions")                    # label/name of the X axis --> Feel free to change this. 

plot.soc_comp

```

```{r}
install.packages("officer")
install.packages("rvg")

library(officer)
library(rvg)

## Output to PPT
p_dml <- rvg::dml(ggobj = plot.soc_comp) # name of your ggplot2 object

read_pptx() %>%
    add_slide(layout = "Title and Content", master = "Office Theme") %>%
    ph_with(value = p_dml, 
            location = ph_location(type = "body",
                                   width = 10, # You can change the width of your output ppt
                                   height = 5)) %>% # You can change the height of your output ppt
    print(target = "figure_socialcomparison.pptx")
```

#最后自信做IV,然后DV还是DV，画regression model
#k)Regression in terms of Moderation Relationship
#do moderator one by one 
#confidence asscoiated with DVs (speculations--more influential for people who are more confident)
```{r}
mod_interaction <- mod_int <- lm(likability_1 ~Condition+confidence1+Gender+#other covariants, 
                   data = dt)
dt
summary(mod_interaction)
confint(mod_interaction)

```

#l)Regression in terms of Mediation Relationship #how to measure this, can I use one chunk of codes to get the mediation relationship or do I need to seperate to 3 parts:
mediation effect = coeffeient * coeffeient 
a)measure the relationship between conditions and confidence (perfect --> highest confidence)
b)measure the relationship between confidence and shopping intention (positivetly related) & likability
c)measure the relationship between conditions and shopping intention & likability (perfect --> highest shopping intentions)

And see if the three relationships are consistent
```{r}
ggplot(dt_f, aes(x=Condition, y=confidence2)) + 
  geom_point() +
  geom_smooth(method=lm, 
              formula= y~x)

mod_cond_conf2 <- lm(confidence2~Condition, 
                   data = dt_f)
summary(mod_cond_conf2)
mod_cond_conf2_out <- tidy(mod_cond_conf2)
#section before is unnecessary 

ggplot(dt_f, aes(x=confidence2, y=si_myself_1)) + 
  geom_point() +
  geom_smooth(method=lm, 
              formula= y~x)

mod_conf2_int <- lm(si_myself_1~confidence2, 
                   data = dt_f)

summary(mod_conf2_int)
mod_conf2_int_out <- tidy(mod_conf2_int)

```

#k) Recode Categorical Variable
```{r}
gender<-c("m","f","f","unkn","f","f","f","f","f","f","f","m","f","f","f","f","f","f","f","f","f","m","f","f","f","f","f","f","f","f","f","f","f","f","f","m","m","f","f","f")
age<-c("18-21","18-21","22-25","22-25","18-21","22-25","18-21","18-21","18-21","22-25","18-21","18-21","18-21","22-25","22-25","22-25","22-25","22-25","18-21","18-21","22-25","18-21","18-21", "18-21","18-21","18-21","29+","18-21","18-21","18-21","22-25","18-21","18-21","18-21","18-21","18-21","22-25","18-21","22-25","18-21")
age<-factor(age)
str(age)
hispanic_origin<-c(F,F,T,T,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F)
str(hispanic_origin)
ethnicity<-c("asian","asian","unknown","unknown","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","white","asian","white","white","white","asian","asian","asian","asian","asian","asian","asian","asian","asian","white","white","white","asian","asian","asian","asian")
str(ethnicity)
ethnicity<-factor(ethnicity)
demographics<-data.frame(age,gender)
household_income<-c("100,000+","100,000+","10,000-40,000","70,000-99,999","10,000-40,000",">10,000","100,000+",">10,000","100,000+","100,000+","100,000+","100,000+","40,000-70,000","40,000-70,000",">10,000","40,000-70,000","40,000-70,000","70,000-99,999","100,000+",">10,000","40,000-70,000","100,000+","40,000-70,000","100,000+","70,000-99,999",">$10,000","10,000-40,000","40,000-70,000",">10,000","100,000+","70,000-99,999","10,000-40,000","10,000-40,000","40,000-70,000","100,000+","100,000+","100,000+","100,000+","10,000-40,000",">10,000")
household_income<-factor(household_income)
appearance_confidence<-c("probably no","probably no","probably yes","probably yes","probably yes","probably no","definetly yes","probably yes","probably yes","probably yes","probably yes","definetly yes","probably yes","probably no","probably yes","probably no","probably yes","probably yes","probably no","probably yes","definetly yes","probably no","probably no","probably yes","probably yes","probably yes","probably yes","probably yes","probably yes","probably no","probably yes","probably no","probably yes","probably no","probably no","probably yes","definetly yes","probably no", "definetly no","probably no" )
appearance_confidence<-factor(appearance_confidence)
str(appearance_confidence)
influencer_follow_count<-c("1-5","10+","1-5","6-10","0","6-10","10+","10+","1-5","10+","10+","10+","10+","10+","10+","10+","10+","6-10","10+","1-5","10+","1-5","1-5","10+","1-5","6-10","1-5","10+","1-5","10+","10+","1-5","10+","1-5","1-5","1-5","1-5","0","10+","10+")
influencer_follow_count<-factor(influencer_follow_count)
str(influencer_follow_count)
hours_spent_on_media<-c("1-3",">3","<1","<1","1-3","<1",">3","1-3",">3","1-3","1-3",">3",">3","1-3","1-3",">3","1-3","1-3","1-3",">3",">3","1-3","1-3","1-3","1-3",">3","1-3",">3",">3","1-3",">3",">3","1-3",">3",">3","1-3","1-3","1-3","<1",">3")
hours_spent_on_media<-factor(hours_spent_on_media)
demographics<-data.frame(gender,age,hispanic_origin,ethnicity,household_income,appearance_confidence)
str(demographics)
previous_exposure<-data.frame(influencer_follow_count,hours_spent_on_media)
print.data.frame(demographics)
print.data.frame(previous_exposure)
pre_experiment<-cbind(demographics,previous_exposure)
print.data.frame(pre_experiment)
```

#f) export data
```{r}
write.table(dt, file="group5_cleaned_data.csv", sep=",")
write.table(previous_exposure, file="previous_exposure.csv", sep=",")
write.table(demographics, file="demographic.csv", sep=",")
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


---
title: "Honor Thesis 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

---
title: "Thesis Honor"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

#a) Part 1: Package Installed
```{r}
#install.packages("tidyverse") 
#install.packages("psych") 
#install.packages("ggplot2")
library(tidyverse) 
library(psych)
```

#b) Data Import
```{r}
#Change this to a relative
dt <- read_csv("../data/Cleaned.csv")
```

#c) Calculate reliabilities
moderator is the gender of participants
```{r}
# Calculate reliabilities for likability measures
dt <- dt %>% 
  mutate(likability_1_alpha = alpha(select(., starts_with("14、喜爱度"), starts_with("18、喜爱度"), starts_with("22、好感度")))$total_rel,
         likability_2_alpha = alpha(select(., starts_with("30、喜爱度")))$total_rel)

```
#d)Calculate means
```{r}
# Calculate means for likability measures
dt <- dt %>% 
  rowwise() %>% 
  mutate(likability_1_mean = mean(select(., starts_with("14、喜爱度"), starts_with("18、喜爱度"), starts_with("22、好感度")), na.rm = TRUE),
         likability_2_mean = mean(select(., starts_with("30、喜爱度")), na.rm = TRUE))


```

#e) Subset data
```{r}
# Subset data and calculate means and standard deviations by gender and condition
dt_summary <- dt %>% 
  group_by(Gender, Condition) %>% 
  summarize(mean_likability_1 = mean(as.numeric(likability_1_mean), na.rm = TRUE),
            sd_likability_1 = sd(as.numeric(likability_1_mean), na.rm = TRUE),
            mean_likability_2 = mean(as.numeric(likability_2_mean), na.rm = TRUE),
            sd_likability_2 = sd(as.numeric(likability_2_mean), na.rm = TRUE),
            .groups = "drop")



```

```{r}
dt_m <- dt %>% 
  filter(Gender == 2)

dt_per_likability_2 <- dt_m %>% 
  filter(Condition == "Perfect") %>%
  select(likability_2)

dt_ave_likability_2 <- dt_m %>% 
  filter(Condition == "Average") %>%
  select(likability_2)

dt_over_likability_2 <- dt_m %>% 
  filter(Condition == "Overweight") %>%
  select(likability_2)
```

```{r}
mean(dt_per_likability_1$likability_1)
sd(dt_per_likability_1$likability_1)

mean(dt_per_likability_2$likability_2)
sd(dt_per_likability_2$likability_2)

mean(dt_per_likability_3$likability_3)
sd(dt_per_likability_3$likability_3)

mean(dt_per_likability_4$likability_4)
sd(dt_per_likability_4$likability_4)
```

#f)Likability Visualize data 画图
```{r}
library(ggplot2) # ggplot2 is R's powerhouse for visualization

ggplot(dt, 
       aes(x=likability_1)) + 
  geom_histogram(binwidth=0.1)
```

#) Analyze data
```{r}
library(tidyverse)
library(rstatix)
likability_1 <- lm(likability_1~condition2, data = dt)

summary(mod_fear_3)
confint(mod_fear_3)
```

```{r}
# Load packages
library(Publish)
library(ggplot2)
library(ggsci)
library(ggpubr)
library(officer)
library(rvg)

# Compute means and CIs
dt_plot_means <- dt_m %>%
  group_by(Condition) %>%
  summarise(mean = mean(likability_1),
            lower = mean - qnorm(0.975) * sd(likability_1) / sqrt(n()),
            upper = mean + qnorm(0.975) * sd(likability_1) / sqrt(n())) %>%
  select(labels = Condition, mean, lower, upper)

# Create plot
plot.fear <- ggplot(dt_plot_means, aes(x = labels, y = mean, fill = labels)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8) +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                position = position_dodge(width = 0.8), 
                width = 0.06, 
                size = 0.5, 
                colour = "gray30") +
  scale_fill_nejm() +
  coord_cartesian(ylim = c(1, 5)) +
  labs(x = "Conditions", y = "95% CIs of Group Means") +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        text = element_text(family = "sans", size = 10),
        legend.title = element_text(size = 10))

# Output to PPT
p_dml <- rvg::dml(ggobj = plot.fear)
read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = p_dml, 
          location = ph_location(type = "body", width = 10, height = 5)) %>%
  print(target = "figure_group_means.pptx")

```

#g)shopping intention to split alpha
```{r}
dt_si_myself_1 <- dt %>% 
  select(starts_with("16、购买意愿2"), starts_with("15、购买意愿1"), 
         starts_with("19、购买意愿1"), starts_with("20、购买意愿2"),
         starts_with("23、购买意愿1"), starts_with("24、购买意愿2"))
alpha(dt_si_myself_1) # This is the "alpha" function from the psych package to calculate Cronbach's alpha --- one of the most commonly used metric for reliability

dt_si_myself_2 <- dt %>% 
  select(starts_with("31、购买意愿1"), starts_with("32、购买意愿2"))
alpha(dt_si_myself_2)

dt_si_family_1 <- dt %>% 
  select(starts_with("16、购买意愿3"),
         starts_with("20、购买意愿3"),
         starts_with("24、购买意愿3"))
alpha(dt_si_family_1)

dt_si_family_2 <- dt %>% 
  select(starts_with("32、购买意愿4"))
alpha(dt_si_family_2)
```

#h)shopping intention to split mean
```{r}
dt <- dt %>%
  mutate(si_myself_1 = rowMeans(select(dt,  
                                starts_with("15、购买意愿1"),  
                                starts_with("16、购买意愿2"),
                                starts_with("19、购买意愿1"),
                                starts_with("20、购买意愿2"),
                                starts_with("23、购买意愿1"),
                                starts_with("24、购买意愿2")),
                         na.rm=T)) %>%
  mutate(si_myself_2 = rowMeans(select(dt,  
                                 starts_with("31、购买意愿1"),
                                 starts_with("32、购买意愿2")), 
                         na.rm=T)) %>%
  mutate(si_family_1 = rowMeans(select(dt,  
                                 starts_with("16、购买意愿3"),
                                 starts_with("20、购买意愿3"),
                                 starts_with("24、购买意愿3")), 
                         na.rm=T)) %>%
  mutate(si_family_2 = rowMeans(select(dt,  
                                 starts_with("32、购买意愿3")), 
                         na.rm=T))

```
#i)  Filter the data based on the different shopping conditions
```{r}
dt_m <- dt

dt_per_likability_1 <- dt_m %>% 
  filter(Condition == "Perfect") %>%
  select(likability_1)

dt_ave_likability_1 <- dt_m %>% 
  filter(Condition == "Average") %>%
  select(likability_1)

dt_over_likability_1 <- dt_m %>% 
  filter(Condition == "Overweight") %>%
  select(likability_1)
```

```{r}
dt_per_likability_2 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_2)

dt_ave_likability_2 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_2)

dt_over_likability_2 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_2)
```

```{r}
dt_per_likability_3 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_3)

dt_ave_likability_3 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_3)

dt_over_likability_3 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_3)
```

```{r}
dt_per_likability_4 <- dt %>% 
  filter(Condition == "Perfect") %>%
  select(likability_4)

dt_ave_likability_4 <- dt %>% 
  filter(Condition == "Average") %>%
  select(likability_4)

dt_over_likability_4 <- dt %>% 
  filter(Condition == "Overweight") %>%
  select(likability_4)
```

```{r}
mean(dt_per_likability_1$likability_1)
sd(dt_per_likability_1$likability_1)

mean(dt_per_likability_2$likability_2)
sd(dt_per_likability_2$likability_2)

mean(dt_per_likability_3$likability_3)
sd(dt_per_likability_3$likability_3)

mean(dt_per_likability_4$likability_4)
sd(dt_per_likability_4$likability_4)
```

#j)Plot the shopping intentions
```{r}
install.packages("rstatix")
library(rstatix)
```

```{r}
install.packages("Publish")
library(Publish)
```
```{r}
dt_plot_means <- ci.mean(soc_comp~condition,
                         data=dt)
dt_plot_means <- as_tibble(dt_plot_means)
dt_plot_means <- as_tibble(dt_plot_means)%>%
  select(labels, mean, lower, upper)
```

```{r}
install.packages("ggpubr")
install.packages("ggsci")

library(ggplot2)
library(ggsci)
library(ggpubr)

apatheme=theme_bw()+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        text=element_text(family='sans',size=10),
        legend.title = element_text(size = 10))

dodge = position_dodge(width=0.8)
```

```{r}
plot.soc_comp <- ggplot(dt_plot_means, # Your dataset that contains labels, means, and lower and upper bounds
                    aes(x = labels, # this corresponds to the variable that specifies groups/conditions
                        y = mean,  # this corresponds to the variable that records group means
                        fill = labels))+ # this corresponds to the variable that specifies groups/conditions
  scale_fill_nejm()+                    # I am using the color panel for the New England Journal of Medicine. You could change to a different one. 
  geom_bar(stat='identity', position = dodge, width = 0.8)+  
  coord_cartesian(ylim=c(1,5))+         # you should use the scale of your DV (5 points? 7 points?)
  geom_errorbar(aes(ymin = lower,       # this corresponds to the variable that records the lower bound for the 95% CI.
                    ymax = upper),      # this corresponds to the variable that records the lower bound for the 95% CI.
                size=0.5, 
                position=dodge, 
                width=0.06, 
                colour="gray30")+
  apatheme+
  ylab("95% CIs of Group Means")+       # label/name of the Y axis --> Feel free to change this. 
  xlab("Conditions")                    # label/name of the X axis --> Feel free to change this. 

plot.soc_comp

```

```{r}
install.packages("officer")
install.packages("rvg")

library(officer)
library(rvg)

## Output to PPT
p_dml <- rvg::dml(ggobj = plot.soc_comp) # name of your ggplot2 object

read_pptx() %>%
    add_slide(layout = "Title and Content", master = "Office Theme") %>%
    ph_with(value = p_dml, 
            location = ph_location(type = "body",
                                   width = 10, # You can change the width of your output ppt
                                   height = 5)) %>% # You can change the height of your output ppt
    print(target = "figure_socialcomparison.pptx")
```

#最后自信做IV,然后DV还是DV，画regression model
#k)Regression in terms of Moderation Relationship
```{r}
mod_interaction <- mod_int <- lm(likability_1 ~Condition+confidence1+Gender+#other covariants, 
                   data = dt)
dt
summary(mod_interaction)
confint(mod_interaction)

```

#l)Regression in terms of Mediation Relationship
mediation effect = coeffeient * coeffeient 
a)measure the relationship between conditions and confidence (perfect --> highest confidence)
b)measure the relationship between confidence and shopping intention (positivetly related) & likability
c)measure the relationship between conditions and shopping intention & likability (perfect --> highest shopping intentions)

And see if the three relationships are consistent
```{r}
ggplot(dt_f, aes(x=Condition, y=confidence2)) + 
  geom_point() +
  geom_smooth(method=lm, 
              formula= y~x)

mod_cond_conf2 <- lm(confidence2~Condition, 
                   data = dt_f)
summary(mod_cond_conf2)
mod_cond_conf2_out <- tidy(mod_cond_conf2)
#section before is unnecessary 

ggplot(dt_f, aes(x=confidence2, y=si_myself_1)) + 
  geom_point() +
  geom_smooth(method=lm, 
              formula= y~x)

mod_conf2_int <- lm(si_myself_1~confidence2, 
                   data = dt_f)

summary(mod_conf2_int)
mod_conf2_int_out <- tidy(mod_conf2_int)

```

#k) Recode Categorical Variable
```{r}
gender<-c("m","f","f","unkn","f","f","f","f","f","f","f","m","f","f","f","f","f","f","f","f","f","m","f","f","f","f","f","f","f","f","f","f","f","f","f","m","m","f","f","f")
age<-c("18-21","18-21","22-25","22-25","18-21","22-25","18-21","18-21","18-21","22-25","18-21","18-21","18-21","22-25","22-25","22-25","22-25","22-25","18-21","18-21","22-25","18-21","18-21", "18-21","18-21","18-21","29+","18-21","18-21","18-21","22-25","18-21","18-21","18-21","18-21","18-21","22-25","18-21","22-25","18-21")
age<-factor(age)
str(age)
hispanic_origin<-c(F,F,T,T,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F,F)
str(hispanic_origin)
ethnicity<-c("asian","asian","unknown","unknown","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","asian","white","asian","white","white","white","asian","asian","asian","asian","asian","asian","asian","asian","asian","white","white","white","asian","asian","asian","asian")
str(ethnicity)
ethnicity<-factor(ethnicity)
demographics<-data.frame(age,gender)
household_income<-c("100,000+","100,000+","10,000-40,000","70,000-99,999","10,000-40,000",">10,000","100,000+",">10,000","100,000+","100,000+","100,000+","100,000+","40,000-70,000","40,000-70,000",">10,000","40,000-70,000","40,000-70,000","70,000-99,999","100,000+",">10,000","40,000-70,000","100,000+","40,000-70,000","100,000+","70,000-99,999",">$10,000","10,000-40,000","40,000-70,000",">10,000","100,000+","70,000-99,999","10,000-40,000","10,000-40,000","40,000-70,000","100,000+","100,000+","100,000+","100,000+","10,000-40,000",">10,000")
household_income<-factor(household_income)
appearance_confidence<-c("probably no","probably no","probably yes","probably yes","probably yes","probably no","definetly yes","probably yes","probably yes","probably yes","probably yes","definetly yes","probably yes","probably no","probably yes","probably no","probably yes","probably yes","probably no","probably yes","definetly yes","probably no","probably no","probably yes","probably yes","probably yes","probably yes","probably yes","probably yes","probably no","probably yes","probably no","probably yes","probably no","probably no","probably yes","definetly yes","probably no", "definetly no","probably no" )
appearance_confidence<-factor(appearance_confidence)
str(appearance_confidence)
influencer_follow_count<-c("1-5","10+","1-5","6-10","0","6-10","10+","10+","1-5","10+","10+","10+","10+","10+","10+","10+","10+","6-10","10+","1-5","10+","1-5","1-5","10+","1-5","6-10","1-5","10+","1-5","10+","10+","1-5","10+","1-5","1-5","1-5","1-5","0","10+","10+")
influencer_follow_count<-factor(influencer_follow_count)
str(influencer_follow_count)
hours_spent_on_media<-c("1-3",">3","<1","<1","1-3","<1",">3","1-3",">3","1-3","1-3",">3",">3","1-3","1-3",">3","1-3","1-3","1-3",">3",">3","1-3","1-3","1-3","1-3",">3","1-3",">3",">3","1-3",">3",">3","1-3",">3",">3","1-3","1-3","1-3","<1",">3")
hours_spent_on_media<-factor(hours_spent_on_media)
demographics<-data.frame(gender,age,hispanic_origin,ethnicity,household_income,appearance_confidence)
str(demographics)
previous_exposure<-data.frame(influencer_follow_count,hours_spent_on_media)
print.data.frame(demographics)
print.data.frame(previous_exposure)
pre_experiment<-cbind(demographics,previous_exposure)
print.data.frame(pre_experiment)
```

#f) export data
```{r}
write.table(dt, file="group5_cleaned_data.csv", sep=",")
write.table(previous_exposure, file="previous_exposure.csv", sep=",")
write.table(demographics, file="demographic.csv", sep=",")
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

